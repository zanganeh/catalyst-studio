# Story 6.2: Implement Centralized Hash System

## Status
Approved

## Story
**As a** system architect,  
**I want** to create a centralized hash system at the data layer,  
**so that** all content type changes (UI or AI) are tracked consistently

## Acceptance Criteria
1. SHA-256 hash generated for every content type state
2. Hash calculation triggered on any data change
3. Works for both UI edits and AI tool modifications
4. Hash stored with timestamp and change source
5. Deterministic JSON serialization ensures consistent hashing
6. Hash calculation excludes volatile fields (timestamps, IDs)
7. All hash operations are properly unit tested

## Tasks / Subtasks
- [x] Git Setup (REQUIRED FIRST TASK)
  - [x] Checkout and update main: `git checkout main && git pull origin main`
  - [x] Create feature branch: `git checkout -b feature/6-2-hash-system`
- [x] Create Versioning Directory Structure (REQUIRED)
  - [x] Create new directory: `mkdir -p /lib/sync/versioning`
  - [x] Create tests directory: `mkdir -p /lib/sync/versioning/__tests__`
  - [x] Verify directory structure is created correctly
- [x] Create Database Schema for Version History (AC: 4)
  - [x] Create new Prisma migration for content_type_versions table
  - [x] Add required columns: id, type_key, version_hash, parent_hash, content_snapshot, change_source, author, created_at, message
  - [x] Add indexes: idx_type_versions on (type_key, created_at), idx_version_hash on (version_hash)
  - [x] Run migration to update database
- [x] Implement ContentTypeHasher Class (AC: 1, 2, 5, 6)
  - [x] Create `/lib/sync/versioning/ContentTypeHasher.ts`
  - [x] Implement `calculateHash(contentType)` method using crypto SHA-256
  - [x] Implement `normalize(contentType)` for deterministic JSON serialization
  - [x] Exclude volatile fields (timestamps, IDs) from hash calculation
  - [x] Add deterministic property sorting for consistent hashing
- [x] Integrate Hash Calculation with Data Layer (AC: 2, 3)
  - [x] Update `/lib/services/content-type-service.ts` to calculate hash on create
  - [x] Update content type update methods to recalculate hash
  - [x] Ensure AI tools trigger hash calculation through service layer
  - [x] Add hash calculation to all data modification paths
- [x] Implement Version History Tracking (AC: 4)
  - [x] Create `/lib/sync/versioning/VersionHistoryManager.ts`
  - [x] Implement `onDataChange(source: 'UI' | 'AI' | 'SYNC')` method
  - [x] Store hash with timestamp and change source in content_type_versions table
  - [x] Link new versions to parent versions via parent_hash
  - [x] Create full content type snapshot per version
- [x] Add Unit Tests (AC: 7)
  - [x] Create `__tests__/ContentTypeHasher.test.ts`
  - [x] Test deterministic hash generation
  - [x] Test volatile field exclusion
  - [x] Test version history tracking
  - [x] Test integration with content type service
  - [x] Verify hash consistency across different change sources
- [x] Integration Testing
  - [x] Test UI edits trigger hash calculation
  - [x] Test AI tool modifications trigger hash calculation
  - [x] Test version history is properly maintained
  - [x] Verify parent-child relationships in version tree
- [x] Submit PR (REQUIRED FINAL TASK)
  - [x] Push branch: `git push -u origin feature/6-2-hash-system`
  - [x] Create PR from feature branch → main branch
  - [x] PR Title: "Epic 6 Story 2: Implement Centralized Hash System"
  - [x] Link PR to story in description

## Dev Notes

### GitFlow Workflow
Branch Name: feature/6-2-hash-system  
Base Branch: main  
PR Target: main  

Git Commands:
1. Setup: `git checkout main && git pull origin main`
2. Create: `git checkout -b feature/6-2-hash-system`
3. Commit: Use conventional commits (feat:, fix:, docs:, etc.)
4. Push: `git push -u origin feature/6-2-hash-system`
5. PR: Create PR to main branch with title "Epic 6 Story 2: Implement Centralized Hash System"

### Source Tree Context
[Source: Epic 6 Brownfield Architecture & Story 6.1 Implementation]

**Existing Structure** (from Story 6.1):
```
/lib/sync/
├── engine/
│   └── SyncEngine.ts          # Main sync orchestrator
├── extractors/
│   └── database-extractor.js  # Extracts content types
├── transformers/
│   └── optimizely-transformer.js
├── adapters/
│   └── optimizely-api-client.js
├── types/
│   └── sync.ts                # TypeScript type definitions
└── utils/                     # Utility files
```

**New Additions for Story 6.2**:
```
/lib/sync/versioning/           # NEW directory for versioning system
├── ContentTypeHasher.ts        # Hash calculation logic
└── VersionHistoryManager.ts    # Version tracking logic
```

### Database Schema
[Source: Epic 6 Brownfield PRD - Section 6.2 & 7.1]

**New Table: content_type_versions**
```sql
CREATE TABLE content_type_versions (
  id INTEGER PRIMARY KEY,
  type_key TEXT NOT NULL,
  version_hash TEXT UNIQUE NOT NULL,
  parent_hash TEXT,
  content_snapshot JSON NOT NULL,
  change_source TEXT CHECK(change_source IN ('UI', 'AI', 'SYNC')),
  author TEXT,
  created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
  message TEXT
);

CREATE INDEX idx_type_versions ON content_type_versions(type_key, created_at);
CREATE INDEX idx_version_hash ON content_type_versions(version_hash);
```

### Technical Implementation Details
[Source: Epic 6 Brownfield PRD - Section 6.2 Technical Design]

**Hash Output Specification**:
- **Format**: SHA-256 produces a 64-character hexadecimal string
- **Example**: `e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855`
- **Consistency**: Same input always produces same hash (deterministic)
- **Performance Target**: Hash calculation should complete in <10ms for typical content type

**ContentTypeHasher Class Structure**:
```typescript
// /lib/sync/versioning/ContentTypeHasher.ts
import { createHash } from 'crypto';

export class ContentTypeHasher {
  calculateHash(contentType: any): string {
    // Deterministic JSON serialization
    const normalized = this.normalize(contentType);
    return createHash('sha256').update(JSON.stringify(normalized)).digest('hex');
  }
  
  private normalize(contentType: any): any {
    // Remove volatile fields (id, timestamps, etc.)
    const { id, createdAt, updatedAt, ...stable } = contentType;
    
    // Sort properties deterministically
    return this.sortObjectKeys(stable);
  }
  
  private sortObjectKeys(obj: any): any {
    // Recursive sorting of all object keys
    // Ensures consistent JSON stringification
  }
}
```

**VersionHistoryManager Integration**:
```typescript
// /lib/sync/versioning/VersionHistoryManager.ts
export class VersionHistoryManager {
  constructor(
    private prisma: PrismaClient,
    private hasher: ContentTypeHasher
  ) {}
  
  async onDataChange(
    contentType: any,
    source: 'UI' | 'AI' | 'SYNC',
    author?: string,
    message?: string
  ): Promise<void> {
    const newHash = this.hasher.calculateHash(contentType);
    const currentVersion = await this.getCurrentVersion(contentType.key);
    
    await this.prisma.contentTypeVersion.create({
      data: {
        type_key: contentType.key,
        version_hash: newHash,
        parent_hash: currentVersion?.version_hash || null,
        content_snapshot: contentType,
        change_source: source,
        author: author || 'system',
        message: message
      }
    });
  }
}
```

### Integration Points
[Source: Epic 6 Brownfield Architecture - Component Integration, Section 5.2]

**Content Type Service Integration**:
[Source: docs/epic6-architecture.md - Component Architecture]
- Modify `/lib/services/content-type-service.ts` to use VersionHistoryManager
- Add hash calculation to `createContentType()` method
- Add hash calculation to `updateContentType()` method
- Ensure all modification paths go through versioning

**AI Tools Integration**:
[Source: Epic 5 Implementation & docs/epic6-architecture.md - Integration Strategy]
- AI tools already use content-type-service (from Story 5.x implementation)
- No direct modifications needed to AI tools
- Hash calculation happens automatically at service layer

**Database Connection**:
[Source: Existing project configuration]
- Prisma client configuration: `/lib/db/prisma.ts`
- Database location: `./prisma/dev.db` (SQLite)
- Connection managed by existing Prisma setup

### Important Notes from Previous Story (6.1)
[Source: Story 6.1 Dev Agent Record]

1. **TypeScript Wrappers**: Story 6.1 used MVP approach with `any` types - continue this pattern for quick implementation
2. **Error Handling Pattern**: Use comprehensive try-catch with partial failure support (continue after individual failures)
   ```typescript
   try {
     // Hash calculation logic
   } catch (error) {
     console.error(`Hash calculation failed for ${contentType.key}:`, error);
     // Log error but don't stop the sync process
     await this.logError(error, 'HASH_CALCULATION_FAILED', contentType);
   }
   ```
3. **Environment Variables**: Already configured for Optimizely OAuth, no new env vars needed for hashing
4. **Testing Approach**: Create `__tests__` folders adjacent to source files

### MVP Simplifications
[Source: Epic 6 Brownfield PRD - MVP Context]

**What to focus on**:
- Basic hash calculation that works reliably
- Simple version tracking without complex branching
- Integration with existing service layer

**What NOT to worry about**:
- Perfect TypeScript types - use `any` where needed for MVP
- Complex merge scenarios - just track linear history for now
- Performance optimization - make it work first
- Rollback implementation - that's Phase 4

### Testing Standards
[Source: Existing project structure from Story 6.1]

- **Test Framework**: Jest (already configured)
- **Test Location**: Create `/lib/sync/versioning/__tests__/` directory
- **Test Files**: 
  - `ContentTypeHasher.test.ts`
  - `VersionHistoryManager.test.ts`
- **Coverage Target**: Focus on critical paths, not 100% coverage for MVP
- **Mock Strategy**: Use Prisma mocks for database operations

### Example Test Cases
```typescript
// ContentTypeHasher.test.ts examples
describe('ContentTypeHasher', () => {
  it('should generate consistent 64-character SHA-256 hash', () => {
    const hasher = new ContentTypeHasher();
    const contentType = { key: 'blog', name: 'Blog Post', fields: [...] };
    const hash = hasher.calculateHash(contentType);
    
    expect(hash).toMatch(/^[a-f0-9]{64}$/); // SHA-256 produces 64 hex chars
    expect(hasher.calculateHash(contentType)).toBe(hash); // Deterministic
  });
  
  it('should exclude volatile fields from hash', () => {
    const hasher = new ContentTypeHasher();
    const type1 = { key: 'blog', name: 'Blog', id: 1, createdAt: new Date() };
    const type2 = { key: 'blog', name: 'Blog', id: 2, createdAt: new Date() };
    
    expect(hasher.calculateHash(type1)).toBe(hasher.calculateHash(type2));
  });
  
  it('should produce different hashes for different content', () => {
    const hasher = new ContentTypeHasher();
    const type1 = { key: 'blog', name: 'Blog Post' };
    const type2 = { key: 'blog', name: 'Blog Article' };
    
    expect(hasher.calculateHash(type1)).not.toBe(hasher.calculateHash(type2));
  });
  
  it('should meet performance benchmark (<10ms)', () => {
    const hasher = new ContentTypeHasher();
    const contentType = { 
      key: 'blog', 
      name: 'Blog Post',
      fields: Array(20).fill({ name: 'field', type: 'string' }) // Typical size
    };
    
    const startTime = performance.now();
    hasher.calculateHash(contentType);
    const endTime = performance.now();
    
    expect(endTime - startTime).toBeLessThan(10); // Should complete in <10ms
  });
});
```

### Prisma Migration Instructions
```bash
# Generate migration
npx prisma migrate dev --name add_content_type_versions

# The migration will be created in prisma/migrations/
# Review the SQL before applying
```

### Dependencies to Install
```bash
# No new dependencies needed - crypto is built into Node.js
# Prisma already installed from previous stories
```

## Change Log
| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2025-01-15 | 1.0 | Initial story creation | Scrum Master (Bob) |
| 2025-01-15 | 1.1 | Added test examples, hash format spec, and performance benchmarks per PO review | Scrum Master (Bob) |
| 2025-01-17 | 1.2 | Added explicit directory creation task, enhanced source references, added error handling patterns and database connection details per PO validation feedback | Scrum Master (Bob) |

## Dev Agent Record
*Implementation completed on 2025-01-17*

### Agent Model Used
Claude Opus 4.1 (claude-opus-4-1-20250805)

### Debug Log References
- Prisma migration successful: `20250817080752_add_content_type_versions`
- All tests passing: 29 tests across 3 test suites
- No TypeScript errors detected
- No linting issues found

### Completion Notes List
1. ✅ Created feature branch from main
2. ✅ Created versioning directory structure at `/lib/sync/versioning/`
3. ✅ Implemented Prisma migration for content_type_versions table
4. ✅ Implemented ContentTypeHasher class with deterministic SHA-256 hashing
5. ✅ Implemented VersionHistoryManager for tracking version history
6. ✅ Integrated hash calculation into content-type-service (both create and update)
7. ✅ Updated AI tools to pass 'AI' as source parameter
8. ✅ Created comprehensive unit tests (all passing)
9. ✅ Created integration tests (all passing)
10. ✅ Fixed test assertion ordering issue in integration tests
11. ✅ Submitted PR #27 to main branch

### File List
**Created Files:**
- `/lib/sync/versioning/ContentTypeHasher.ts` - Core hash calculation logic
- `/lib/sync/versioning/VersionHistoryManager.ts` - Version history management
- `/lib/sync/versioning/__tests__/ContentTypeHasher.test.ts` - 10 unit tests
- `/lib/sync/versioning/__tests__/VersionHistoryManager.test.ts` - 13 unit tests  
- `/lib/sync/versioning/__tests__/integration.test.ts` - 6 integration tests
- `/prisma/migrations/20250817080752_add_content_type_versions/migration.sql` - Database migration

**Modified Files:**
- `/prisma/schema.prisma` - Added ContentTypeVersion model
- `/lib/services/content-type-service.ts` - Added source parameter and version tracking
- `/lib/ai-tools/tools/content-types/create-content-type.ts` - Pass 'AI' as source
- `/lib/ai-tools/tools/content-types/update-content-type.ts` - Pass 'AI' as source

**Pull Request:**
- PR #27: https://github.com/zanganeh/catalyst-studio/pull/27
- Title: "Epic 6 Story 2: Implement Centralized Hash System"
- Status: Submitted and ready for review

## QA Results
*QA Review completed on 2025-01-17 by Quinn (Senior Developer & QA Architect)*

### Test Coverage Analysis
**Overall Score: 9.5/10**

#### Code Quality Assessment
1. **Architecture & Design** ✅ Excellent
   - Clean separation of concerns with ContentTypeHasher and VersionHistoryManager
   - Follows Single Responsibility Principle
   - MVP pattern appropriately applied with `any` types for rapid development
   - Error handling follows Story 6.1 pattern (log but don't stop)

2. **Implementation Quality** ✅ Excellent
   - SHA-256 hashing correctly implemented with deterministic serialization
   - Volatile fields properly excluded (id, timestamps, etc.)
   - Recursive key sorting ensures consistent hashing
   - Integration with content-type-service is seamless and non-breaking

3. **Test Coverage** ✅ Comprehensive
   - 29 tests passing across 3 test suites
   - Unit tests: ContentTypeHasher (10 tests), VersionHistoryManager (13 tests)
   - Integration tests: Full workflow testing (6 tests)
   - Performance benchmark test validates <10ms requirement

#### Functional Verification
**End-to-End Testing Results:**
- ✅ Created test website with ID `cmefhb42d0000v8twing20yo7`
- ✅ Content type creation triggers version tracking
- ✅ Content type updates generate new versions with parent links
- ✅ Both UI and AI sources properly tracked in `change_source` field
- ✅ Version hashes are deterministic and consistent
- ✅ Database schema correctly implemented with proper indexes

**Database Verification:**
```sql
-- Query Results:
4 version records found
Sources tracked: UI, AI
Hash format: 64-character SHA-256 (verified)
Content snapshots: Complete JSON stored
```

#### Security & Performance
- ✅ **Security**: No sensitive data exposed in logs or version history
- ✅ **Performance**: Hash calculation well under 10ms threshold
- ✅ **Error Handling**: Graceful failure with logging, doesn't interrupt sync
- ✅ **Database**: Proper indexes on type_key and version_hash for query performance

#### Areas of Excellence
1. **Deterministic Hashing**: Excellent implementation with sorted keys and volatile field exclusion
2. **Version Tracking**: Git-like parent-child relationships properly maintained
3. **Source Attribution**: Clear tracking of changes from UI, AI, and SYNC sources
4. **Test Quality**: Comprehensive test coverage including edge cases and performance

#### Minor Observations (Non-Critical)
1. **TypeScript Types**: MVP approach with `any` types is appropriate but could be enhanced in future iterations
2. **Error Logging**: Console.error used for MVP, production should use proper logging service
3. **Migration Timestamp**: Uses Unix timestamp format in migration filename (acceptable for MVP)

#### Acceptance Criteria Validation
| AC # | Requirement | Status | Evidence |
|------|------------|--------|----------|
| 1 | SHA-256 hash for every content type state | ✅ PASS | Verified in ContentTypeHasher.ts and database |
| 2 | Hash calculation triggered on data change | ✅ PASS | Integrated in content-type-service create/update |
| 3 | Works for UI and AI modifications | ✅ PASS | Both sources tracked, AI tools pass 'AI' source |
| 4 | Hash stored with timestamp and source | ✅ PASS | Database records show all required fields |
| 5 | Deterministic JSON serialization | ✅ PASS | Key sorting and normalization implemented |
| 6 | Excludes volatile fields | ✅ PASS | id, timestamps, _id fields excluded |
| 7 | All operations unit tested | ✅ PASS | 29 tests covering all scenarios |

### Recommendation
**APPROVED FOR MERGE** ✅

The implementation successfully meets all acceptance criteria with high code quality and comprehensive test coverage. The versioning system is production-ready for MVP deployment. PR #27 demonstrates excellent engineering practices and should be merged to main branch.

### Test Artifacts
- Screenshot: `qa-versioning-test-content-types.png`
- Test Website ID: `cmefhb42d0000v8twing20yo7`
- Database Verification: 4 version records confirmed
- All 29 tests passing