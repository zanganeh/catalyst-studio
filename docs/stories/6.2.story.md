# Story 6.2: Implement Centralized Hash System

## Status
Approved

## Story
**As a** system architect,  
**I want** to create a centralized hash system at the data layer,  
**so that** all content type changes (UI or AI) are tracked consistently

## Acceptance Criteria
1. SHA-256 hash generated for every content type state
2. Hash calculation triggered on any data change
3. Works for both UI edits and AI tool modifications
4. Hash stored with timestamp and change source
5. Deterministic JSON serialization ensures consistent hashing
6. Hash calculation excludes volatile fields (timestamps, IDs)
7. All hash operations are properly unit tested

## Tasks / Subtasks
- [ ] Git Setup (REQUIRED FIRST TASK)
  - [ ] Checkout and update main: `git checkout main && git pull origin main`
  - [ ] Create feature branch: `git checkout -b feature/6-2-hash-system`
- [ ] Create Versioning Directory Structure (REQUIRED)
  - [ ] Create new directory: `mkdir -p /lib/sync/versioning`
  - [ ] Create tests directory: `mkdir -p /lib/sync/versioning/__tests__`
  - [ ] Verify directory structure is created correctly
- [ ] Create Database Schema for Version History (AC: 4)
  - [ ] Create new Prisma migration for content_type_versions table
  - [ ] Add required columns: id, type_key, version_hash, parent_hash, content_snapshot, change_source, author, created_at, message
  - [ ] Add indexes: idx_type_versions on (type_key, created_at), idx_version_hash on (version_hash)
  - [ ] Run migration to update database
- [ ] Implement ContentTypeHasher Class (AC: 1, 2, 5, 6)
  - [ ] Create `/lib/sync/versioning/ContentTypeHasher.ts`
  - [ ] Implement `calculateHash(contentType)` method using crypto SHA-256
  - [ ] Implement `normalize(contentType)` for deterministic JSON serialization
  - [ ] Exclude volatile fields (timestamps, IDs) from hash calculation
  - [ ] Add deterministic property sorting for consistent hashing
- [ ] Integrate Hash Calculation with Data Layer (AC: 2, 3)
  - [ ] Update `/lib/services/content-type-service.ts` to calculate hash on create
  - [ ] Update content type update methods to recalculate hash
  - [ ] Ensure AI tools trigger hash calculation through service layer
  - [ ] Add hash calculation to all data modification paths
- [ ] Implement Version History Tracking (AC: 4)
  - [ ] Create `/lib/sync/versioning/VersionHistoryManager.ts`
  - [ ] Implement `onDataChange(source: 'UI' | 'AI' | 'SYNC')` method
  - [ ] Store hash with timestamp and change source in content_type_versions table
  - [ ] Link new versions to parent versions via parent_hash
  - [ ] Create full content type snapshot per version
- [ ] Add Unit Tests (AC: 7)
  - [ ] Create `__tests__/ContentTypeHasher.test.ts`
  - [ ] Test deterministic hash generation
  - [ ] Test volatile field exclusion
  - [ ] Test version history tracking
  - [ ] Test integration with content type service
  - [ ] Verify hash consistency across different change sources
- [ ] Integration Testing
  - [ ] Test UI edits trigger hash calculation
  - [ ] Test AI tool modifications trigger hash calculation
  - [ ] Test version history is properly maintained
  - [ ] Verify parent-child relationships in version tree
- [ ] Submit PR (REQUIRED FINAL TASK)
  - [ ] Push branch: `git push -u origin feature/6-2-hash-system`
  - [ ] Create PR from feature branch → main branch
  - [ ] PR Title: "Epic 6 Story 2: Implement Centralized Hash System"
  - [ ] Link PR to story in description

## Dev Notes

### GitFlow Workflow
Branch Name: feature/6-2-hash-system  
Base Branch: main  
PR Target: main  

Git Commands:
1. Setup: `git checkout main && git pull origin main`
2. Create: `git checkout -b feature/6-2-hash-system`
3. Commit: Use conventional commits (feat:, fix:, docs:, etc.)
4. Push: `git push -u origin feature/6-2-hash-system`
5. PR: Create PR to main branch with title "Epic 6 Story 2: Implement Centralized Hash System"

### Source Tree Context
[Source: Epic 6 Brownfield Architecture & Story 6.1 Implementation]

**Existing Structure** (from Story 6.1):
```
/lib/sync/
├── engine/
│   └── SyncEngine.ts          # Main sync orchestrator
├── extractors/
│   └── database-extractor.js  # Extracts content types
├── transformers/
│   └── optimizely-transformer.js
├── adapters/
│   └── optimizely-api-client.js
├── types/
│   └── sync.ts                # TypeScript type definitions
└── utils/                     # Utility files
```

**New Additions for Story 6.2**:
```
/lib/sync/versioning/           # NEW directory for versioning system
├── ContentTypeHasher.ts        # Hash calculation logic
└── VersionHistoryManager.ts    # Version tracking logic
```

### Database Schema
[Source: Epic 6 Brownfield PRD - Section 6.2 & 7.1]

**New Table: content_type_versions**
```sql
CREATE TABLE content_type_versions (
  id INTEGER PRIMARY KEY,
  type_key TEXT NOT NULL,
  version_hash TEXT UNIQUE NOT NULL,
  parent_hash TEXT,
  content_snapshot JSON NOT NULL,
  change_source TEXT CHECK(change_source IN ('UI', 'AI', 'SYNC')),
  author TEXT,
  created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
  message TEXT
);

CREATE INDEX idx_type_versions ON content_type_versions(type_key, created_at);
CREATE INDEX idx_version_hash ON content_type_versions(version_hash);
```

### Technical Implementation Details
[Source: Epic 6 Brownfield PRD - Section 6.2 Technical Design]

**Hash Output Specification**:
- **Format**: SHA-256 produces a 64-character hexadecimal string
- **Example**: `e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855`
- **Consistency**: Same input always produces same hash (deterministic)
- **Performance Target**: Hash calculation should complete in <10ms for typical content type

**ContentTypeHasher Class Structure**:
```typescript
// /lib/sync/versioning/ContentTypeHasher.ts
import { createHash } from 'crypto';

export class ContentTypeHasher {
  calculateHash(contentType: any): string {
    // Deterministic JSON serialization
    const normalized = this.normalize(contentType);
    return createHash('sha256').update(JSON.stringify(normalized)).digest('hex');
  }
  
  private normalize(contentType: any): any {
    // Remove volatile fields (id, timestamps, etc.)
    const { id, createdAt, updatedAt, ...stable } = contentType;
    
    // Sort properties deterministically
    return this.sortObjectKeys(stable);
  }
  
  private sortObjectKeys(obj: any): any {
    // Recursive sorting of all object keys
    // Ensures consistent JSON stringification
  }
}
```

**VersionHistoryManager Integration**:
```typescript
// /lib/sync/versioning/VersionHistoryManager.ts
export class VersionHistoryManager {
  constructor(
    private prisma: PrismaClient,
    private hasher: ContentTypeHasher
  ) {}
  
  async onDataChange(
    contentType: any,
    source: 'UI' | 'AI' | 'SYNC',
    author?: string,
    message?: string
  ): Promise<void> {
    const newHash = this.hasher.calculateHash(contentType);
    const currentVersion = await this.getCurrentVersion(contentType.key);
    
    await this.prisma.contentTypeVersion.create({
      data: {
        type_key: contentType.key,
        version_hash: newHash,
        parent_hash: currentVersion?.version_hash || null,
        content_snapshot: contentType,
        change_source: source,
        author: author || 'system',
        message: message
      }
    });
  }
}
```

### Integration Points
[Source: Epic 6 Brownfield Architecture - Component Integration, Section 5.2]

**Content Type Service Integration**:
[Source: docs/epic6-architecture.md - Component Architecture]
- Modify `/lib/services/content-type-service.ts` to use VersionHistoryManager
- Add hash calculation to `createContentType()` method
- Add hash calculation to `updateContentType()` method
- Ensure all modification paths go through versioning

**AI Tools Integration**:
[Source: Epic 5 Implementation & docs/epic6-architecture.md - Integration Strategy]
- AI tools already use content-type-service (from Story 5.x implementation)
- No direct modifications needed to AI tools
- Hash calculation happens automatically at service layer

**Database Connection**:
[Source: Existing project configuration]
- Prisma client configuration: `/lib/db/prisma.ts`
- Database location: `./prisma/dev.db` (SQLite)
- Connection managed by existing Prisma setup

### Important Notes from Previous Story (6.1)
[Source: Story 6.1 Dev Agent Record]

1. **TypeScript Wrappers**: Story 6.1 used MVP approach with `any` types - continue this pattern for quick implementation
2. **Error Handling Pattern**: Use comprehensive try-catch with partial failure support (continue after individual failures)
   ```typescript
   try {
     // Hash calculation logic
   } catch (error) {
     console.error(`Hash calculation failed for ${contentType.key}:`, error);
     // Log error but don't stop the sync process
     await this.logError(error, 'HASH_CALCULATION_FAILED', contentType);
   }
   ```
3. **Environment Variables**: Already configured for Optimizely OAuth, no new env vars needed for hashing
4. **Testing Approach**: Create `__tests__` folders adjacent to source files

### MVP Simplifications
[Source: Epic 6 Brownfield PRD - MVP Context]

**What to focus on**:
- Basic hash calculation that works reliably
- Simple version tracking without complex branching
- Integration with existing service layer

**What NOT to worry about**:
- Perfect TypeScript types - use `any` where needed for MVP
- Complex merge scenarios - just track linear history for now
- Performance optimization - make it work first
- Rollback implementation - that's Phase 4

### Testing Standards
[Source: Existing project structure from Story 6.1]

- **Test Framework**: Jest (already configured)
- **Test Location**: Create `/lib/sync/versioning/__tests__/` directory
- **Test Files**: 
  - `ContentTypeHasher.test.ts`
  - `VersionHistoryManager.test.ts`
- **Coverage Target**: Focus on critical paths, not 100% coverage for MVP
- **Mock Strategy**: Use Prisma mocks for database operations

### Example Test Cases
```typescript
// ContentTypeHasher.test.ts examples
describe('ContentTypeHasher', () => {
  it('should generate consistent 64-character SHA-256 hash', () => {
    const hasher = new ContentTypeHasher();
    const contentType = { key: 'blog', name: 'Blog Post', fields: [...] };
    const hash = hasher.calculateHash(contentType);
    
    expect(hash).toMatch(/^[a-f0-9]{64}$/); // SHA-256 produces 64 hex chars
    expect(hasher.calculateHash(contentType)).toBe(hash); // Deterministic
  });
  
  it('should exclude volatile fields from hash', () => {
    const hasher = new ContentTypeHasher();
    const type1 = { key: 'blog', name: 'Blog', id: 1, createdAt: new Date() };
    const type2 = { key: 'blog', name: 'Blog', id: 2, createdAt: new Date() };
    
    expect(hasher.calculateHash(type1)).toBe(hasher.calculateHash(type2));
  });
  
  it('should produce different hashes for different content', () => {
    const hasher = new ContentTypeHasher();
    const type1 = { key: 'blog', name: 'Blog Post' };
    const type2 = { key: 'blog', name: 'Blog Article' };
    
    expect(hasher.calculateHash(type1)).not.toBe(hasher.calculateHash(type2));
  });
  
  it('should meet performance benchmark (<10ms)', () => {
    const hasher = new ContentTypeHasher();
    const contentType = { 
      key: 'blog', 
      name: 'Blog Post',
      fields: Array(20).fill({ name: 'field', type: 'string' }) // Typical size
    };
    
    const startTime = performance.now();
    hasher.calculateHash(contentType);
    const endTime = performance.now();
    
    expect(endTime - startTime).toBeLessThan(10); // Should complete in <10ms
  });
});
```

### Prisma Migration Instructions
```bash
# Generate migration
npx prisma migrate dev --name add_content_type_versions

# The migration will be created in prisma/migrations/
# Review the SQL before applying
```

### Dependencies to Install
```bash
# No new dependencies needed - crypto is built into Node.js
# Prisma already installed from previous stories
```

## Change Log
| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2025-01-15 | 1.0 | Initial story creation | Scrum Master (Bob) |
| 2025-01-15 | 1.1 | Added test examples, hash format spec, and performance benchmarks per PO review | Scrum Master (Bob) |
| 2025-01-17 | 1.2 | Added explicit directory creation task, enhanced source references, added error handling patterns and database connection details per PO validation feedback | Scrum Master (Bob) |

## Dev Agent Record
*To be populated by the development agent during implementation*

### Agent Model Used
*To be recorded*

### Debug Log References
*To be recorded*

### Completion Notes List
*To be recorded*

### File List
*To be recorded*

## QA Results
*To be populated by QA agent after implementation*