# Story 4.6b: Website Storage Service Migration

## Status
Draft

## Story
**As a** developer,  
**I want** to migrate the IndexedDB-based Website Storage Service to use the database API,  
**so that** large website data (content, assets, AI context) can be stored on the server and synced across devices.

## Acceptance Criteria
1. Create WebsiteData model for large data storage
2. Implement chunked upload/download endpoints for large data
3. Update WebsiteStorageService to use API instead of IndexedDB
4. Implement offline fallback with sync mechanism
5. Create import/export functionality for website backups
6. Migrate existing IndexedDB data to server

## Tasks / Subtasks
- [ ] Git Setup (REQUIRED FIRST TASK)
  - [ ] Checkout and update develop: `git checkout develop && git pull origin develop`
  - [ ] Create feature branch: `git checkout -b feature/4-6b-website-storage-service`
- [ ] Create WebsiteData Model (AC: 1)
  - [ ] Add to `prisma/schema.prisma`:
    ```prisma
    model WebsiteData {
      id        String   @id @default(cuid())
      websiteId String   @unique
      content   Json?    // Large content data
      assets    Json?    // Asset references
      aiContext Json?    // AI conversation history
      version   Int      @default(1)
      createdAt DateTime @default(now())
      updatedAt DateTime @updatedAt
      
      website Website @relation(fields: [websiteId], references: [id], onDelete: Cascade)
    }
    ```
  - [ ] Add relation to Website model: `websiteData WebsiteData?`
  - [ ] Run migration: `npm run db:migrate -- --name add-website-data`
- [ ] Implement Chunked Transfer System (AC: 2)
  - [ ] Create `/lib/api/chunked-transfer.ts`:
    - Chunk large data into 1MB pieces
    - Track upload sessions
    - Reassemble chunks on server
    - Progress tracking mechanism
  - [ ] Create `/app/api/websites/[id]/upload/route.ts`:
    - POST: Accept chunked uploads
    - Track session state
    - Validate chunk order
  - [ ] Create `/app/api/websites/[id]/download/route.ts`:
    - GET: Stream large data in chunks
    - Support range requests
- [ ] Create Website Data API Routes (AC: 2)
  - [ ] Create `/app/api/websites/[id]/data/route.ts`:
    - GET: Retrieve website data (with optional field selection)
    - PUT: Update website data (support partial updates)
    - Handle large JSON payloads
  - [ ] Add compression for large responses
  - [ ] Implement versioning for conflict resolution
- [ ] Update WebsiteStorageService (AC: 3, 4)
  - [ ] Modify `/lib/storage/website-storage.service.ts`:
    - Create `ApiStorageAdapter` class
    - Replace IndexedDB calls with API calls
    - Keep IndexedDB for offline cache
    - Implement sync queue for offline changes
  - [ ] Update methods:
    - `saveWebsiteData()` - Save to API, cache in IndexedDB
    - `getWebsiteData()` - Try API first, fallback to IndexedDB
    - `syncOfflineChanges()` - Push queued changes when online
  - [ ] Add connection state monitoring
- [ ] Implement Import/Export (AC: 5)
  - [ ] Create `/app/api/websites/[id]/export/route.ts`:
    - GET: Export website as downloadable JSON file
    - Include all data: metadata, content, assets, AI context
    - Add version and timestamp
  - [ ] Create `/app/api/websites/import/route.ts`:
    - POST: Import website from uploaded JSON
    - Validate import structure
    - Handle duplicate detection
    - Support version compatibility
- [ ] Create Migration Service (AC: 6)
  - [ ] Create `/lib/storage/migration-service.ts`:
    - Detect all IndexedDB databases
    - Read data from each database
    - Transform to new format
    - Upload via chunked transfer
    - Track migration progress
    - Handle migration failures
  - [ ] Create `/scripts/migrate-indexed-db.ts`:
    - CLI script for migration
    - Progress reporting
    - Rollback capability
  - [ ] Add to package.json: `"migrate:indexeddb": "tsx scripts/migrate-indexed-db.ts"`
- [ ] Implement Offline Sync (AC: 4)
  - [ ] Create `/lib/storage/sync-manager.ts`:
    - Queue offline changes
    - Detect online/offline state
    - Sync when connection restored
    - Handle conflicts
  - [ ] Add service worker for background sync (optional)
  - [ ] Store sync queue in IndexedDB
- [ ] Testing and Validation (AC: 2, 3, 4, 5, 6)
  - [ ] Create chunked transfer tests:
    - Test upload of 10MB+ data
    - Test interrupted uploads
    - Test download streaming
  - [ ] Create offline tests:
    - Test offline data creation
    - Test sync when online
    - Test conflict resolution
  - [ ] Manual testing checklist:
    - Create website offline
    - Edit website data offline
    - Verify sync when online
    - Export large website
    - Import large website
    - Test with slow connection
  - [ ] Performance testing:
    - Measure chunked transfer speed
    - Test with concurrent uploads
    - Verify memory usage stays reasonable
- [ ] Documentation Updates
  - [ ] Document chunked transfer protocol
  - [ ] Document offline sync behavior
  - [ ] Add troubleshooting guide
  - [ ] Update architecture docs
- [ ] Submit PR (REQUIRED FINAL TASK)
  - [ ] Push branch: `git push -u origin feature/4-6b-website-storage-service`
  - [ ] Create PR from feature branch → develop branch
  - [ ] PR Title: "Epic 4 Story 6b: Website Storage Service Migration"
  - [ ] Link PR to story in description

## Dev Notes

### GitFlow Workflow
Branch Name: feature/4-6b-website-storage-service
Base Branch: develop (NOT main)  
PR Target: develop (NOT main)

Git Commands:
1. Setup: `git checkout develop && git pull origin develop`
2. Create: `git checkout -b feature/4-6b-website-storage-service`
3. Commit: Use conventional commits (feat:, fix:, docs:, etc.)
4. Push: `git push -u origin feature/4-6b-website-storage-service`
5. PR: Create PR to develop branch with title "Epic 4 Story 6b: Website Storage Service Migration"

### IndexedDB Structure
[Source: lib/storage/website-storage.service.ts analysis]

Current IndexedDB databases:
- `catalyst_global` - Website list and metadata
- `website_{id}_config` - Website configuration
- `website_{id}_content` - Content data
- `website_{id}_assets` - Asset references  
- `website_{id}_ai_context` - AI conversation history

Each needs to be migrated to the server while maintaining offline capability.

### Chunked Transfer Design
[Source: Best practices for large data transfers]

```typescript
interface ChunkMetadata {
  sessionId: string;
  totalChunks: number;
  chunkIndex: number;
  chunkSize: number;
  checksum: string;
}

// Upload: Client splits data, sends chunks
// Download: Server streams chunks, client assembles
```

### Offline Sync Strategy
[Source: Progressive Web App patterns]

1. **Write-through cache**: Write to API and IndexedDB
2. **Read-through cache**: Read from API, fallback to IndexedDB
3. **Queue offline changes**: Store in sync queue
4. **Sync on reconnect**: Process queue when online
5. **Conflict resolution**: Server version wins, preserve local as backup

### API Patterns
[Source: Stories 4.3-4.5 established patterns]

- Use existing error handling from `/lib/api/errors.ts`
- Follow response format: `{ data: T } | { error: ErrorType }`
- Use Zod for validation
- React Query for caching

### Integration Verification Requirements
[Source: epic4-prd.md#story-4.6]

Must verify:
- IV1: Module functionality unchanged from user perspective
- IV2: No conflicts with previously migrated modules
- IV3: Consistent patterns with other migrated modules

### Dependencies
This story depends on:
- Story 4.6a: Website core migration (basic Website model and API)
- Story 4.3: API patterns
- Story 4.5: Chunked transfer patterns (if implemented there)

### Testing Standards
[Source: Previous stories]

**Test Configuration:**
- Test framework: Jest + React Testing Library
- Test file location: `__tests__` folders
- Large data tests: Use test fixtures

**Module-Specific Testing Requirements:**
- Test with 10MB+ payloads
- Simulate network interruptions
- Test offline scenarios
- Verify sync integrity
- Test import/export round-trip

### Important Notes

1. **Performance Critical**: Large data handling must not block UI
2. **Memory Management**: Stream large data, don't load all in memory
3. **Offline First**: App must work offline with sync later
4. **Data Integrity**: Checksums for chunks, versioning for conflicts
5. **Migration Safety**: Non-destructive, can rollback if needed
6. **Progress Feedback**: Users need to see upload/download progress

### Relevant Source Tree
```
lib/
├── storage/
│   ├── website-storage.service.ts  (modify)
│   ├── migration-service.ts        (create)
│   └── sync-manager.ts            (create)
├── api/
│   └── chunked-transfer.ts        (create)
app/
└── api/
    └── websites/
        └── [id]/
            ├── data/
            │   └── route.ts        (create)
            ├── upload/
            │   └── route.ts        (create)
            ├── download/
            │   └── route.ts        (create)
            └── export/
                └── route.ts        (create)
```

## Change Log
| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2025-08-12 | 1.0 | Created as part of story split | Bob (Scrum Master) |

## Dev Agent Record
*To be populated during implementation*

### Agent Model Used
*To be populated*

### Debug Log References
*To be populated*

### Completion Notes List
*To be populated*

### File List
*To be populated*

## QA Results
*To be populated during QA review*